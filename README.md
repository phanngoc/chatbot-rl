# Chatbot C√° Nh√¢n H√≥a v·ªõi Reinforcement Learning + OpenAI

D·ª± √°n MVP thi·∫øt k·∫ø chatbot c√° nh√¢n h√≥a s·ª≠ d·ª•ng c√°c thu·∫≠t to√°n Reinforcement Learning, Episodic Memory ti√™n ti·∫øn, v√† t√≠ch h·ª£p v·ªõi OpenAI API ƒë·ªÉ t·∫°o ra tr·∫£i nghi·ªám chat ch·∫•t l∆∞·ª£ng cao.

## üéØ T√≠nh nƒÉng ch√≠nh

### Thu·∫≠t to√°n ch√≠nh ƒë∆∞·ª£c tri·ªÉn khai:

1. **OpenAI Integration** - S·ª≠ d·ª•ng GPT-3.5-turbo/GPT-4 cho high-quality response generation
2. **Experience Replay (ER)** - L∆∞u tr·ªØ v√† replay c√°c tr·∫£i nghi·ªám ƒë·ªÉ tr√°nh catastrophic forgetting
3. **Retrieval-Augmented Episodic Memory** - Vector search v·ªõi FAISS/ChromaDB cho memory retrieval
4. **Episodic Memory Consolidation** - Chuy·ªÉn ƒë·ªïi t·ª´ episodic sang semantic memory (gi·ªëng hippocampus)
5. **Elastic Weight Consolidation (EWC)** - B·∫£o v·ªá tr·ªçng s·ªë quan tr·ªçng khi h·ªçc task m·ªõi
6. **Meta-learning v·ªõi Episodic Memory** - MANN, NTM patterns ƒë·ªÉ h·ªçc c√°ch ch·ªçn l·ªçc tr·∫£i nghi·ªám
7. **Temporal Decay & Importance Weighting** - Qu·∫£n l√Ω tr·ªçng s·ªë memory theo th·ªùi gian v√† importance

## üöÄ C√†i ƒë·∫∑t nhanh

```bash
# Clone repository
git clone <repository_url>
cd chatbot-rl

# C√†i ƒë·∫∑t dependencies
pip install -r requirements.txt

# Setup OpenAI API Key
export OPENAI_API_KEY="your-api-key-here"
```

### 1. Interactive Chat (Terminal)
```bash
python src/main.py --mode interactive
```

### 2. Web Interface
```bash
streamlit run src/app.py
```

### 3. Training v·ªõi data
```bash
python src/main.py --mode train --data examples/sample_training_data.json
```

### 4. Evaluation
```bash
python src/main.py --mode eval --data examples/sample_training_data.json
```

## üß† Ki·∫øn tr√∫c h·ªá th·ªëng

### Experience Replay System
- L∆∞u tr·ªØ (state, action, reward, next_state) tuples
- Prioritized sampling d·ª±a tr√™n importance v√† recency
- T·ª± ƒë·ªông l∆∞u/load buffer

### Retrieval-Augmented Memory
- Vector search v·ªõi FAISS ho·∫∑c ChromaDB
- Embedding-based similarity search
- Forgetting mechanism v·ªõi temporal decay

### Memory Consolidation
- **Summarization**: LLM t√≥m t·∫Øt nhi·ªÅu experiences
- **Graph Integration**: Knowledge graph v·ªõi concepts
- **Distillation**: Fine-tune model weights t·ª´ episodic memories

### Elastic Weight Consolidation
- Fisher Information Matrix ƒë·ªÉ x√°c ƒë·ªãnh importance c·ªßa weights
- Multi-task learning v·ªõi penalty cho weight changes
- Adaptive lambda adjustment

### Meta-learning
- Memory-Augmented Neural Network (MANN)
- Neural Turing Machine (NTM) patterns
- H·ªçc c√°ch select relevant memories

### Temporal Weighting
- Multiple decay functions (exponential, power-law, forgetting curve)
- Importance weighting d·ª±a tr√™n feedback v√† usage
- Access pattern analysis

MIT License - xem file LICENSE ƒë·ªÉ bi·∫øt chi ti·∫øt.

## üôè Acknowledgments

- Transformers library t·ª´ Hugging Face
- FAISS cho vector search
- ChromaDB cho vector database
- Streamlit cho web interface
