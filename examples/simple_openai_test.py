#!/usr/bin/env python3
"""
Simple OpenAI API test cho RL Chatbot
"""

import os
import json
import sys
sys.path.append('../src')

from src.agents.rl_chatbot import RLChatbotAgent

def test_openai_connection():
    """Test basic OpenAI connection"""
    from openai import OpenAI
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå OPENAI_API_KEY environment variable is required!")
        print("   Set it with: export OPENAI_API_KEY='your-api-key-here'")
        return False
    
    try:
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "Hello! This is a connection test."}],
            max_tokens=30
        )
        
        print("‚úÖ OpenAI API connection successful!")
        print(f"Response: {response.choices[0].message.content}")
        print(f"Tokens used: {response.usage.total_tokens}")
        return True
        
    except Exception as e:
        print(f"‚ùå OpenAI API connection failed: {e}")
        return False

def test_rl_chatbot():
    """Test RL Chatbot v·ªõi OpenAI"""
    
    print("\nü§ñ Testing RL Chatbot with OpenAI...")
    
    # Load config
    config_path = os.path.join(os.path.dirname(__file__), '../configs/default.json')
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    # Initialize agent
    agent = RLChatbotAgent(
        openai_model=config.get("openai_model", "gpt-3.5-turbo"),
        api_key=os.getenv("OPENAI_API_KEY"),
        config=config
    )
    
    # Start conversation
    conversation_id = agent.start_conversation()
    print(f"üìã Started conversation: {conversation_id}")
    
    # Test messages
    test_messages = [
        "Xin ch√†o! B·∫°n c√≥ th·ªÉ gi·ªõi thi·ªáu v·ªÅ b·∫£n th√¢n kh√¥ng?",
        "B·∫°n c√≥ th·ªÉ nh·ªõ ƒë∆∞·ª£c nh·ªØng g√¨ ch√∫ng ta ƒë√£ n√≥i kh√¥ng?",
        "H√£y k·ªÉ cho t√¥i m·ªôt c√¢u chuy·ªán ng·∫Øn."
    ]
    
    for i, message in enumerate(test_messages, 1):
        print(f"\n--- Test {i} ---")
        print(f"üë§ User: {message}")
        
        try:
            result = agent.process_message(message)
            
            print(f"ü§ñ Bot: {result['response']}")
            print(f"üìä Memories used: {result['relevant_memories_count']}")
            print(f"‚è±Ô∏è  Response time: {result['response_time_ms']:.2f}ms")
            
            if result.get('openai_usage'):
                usage = result['openai_usage']
                print(f"üí∞ Tokens: {usage.get('total_tokens', 0)} (prompt: {usage.get('prompt_tokens', 0)}, completion: {usage.get('completion_tokens', 0)})")
            
            if result.get('api_error'):
                print(f"‚ö†Ô∏è  API Error: {result['api_error']}")
                
        except Exception as e:
            print(f"‚ùå Error processing message: {e}")
    
    # Get system status
    print(f"\nüìà System Status:")
    status = agent.get_system_status()
    print(f"   - Model: {status['model_info']['openai_model']}")
    print(f"   - Total interactions: {status['performance_metrics']['total_interactions']}")
    print(f"   - Neural parameters: {status['model_info']['neural_parameters']:,}")

def main():
    """Main test function"""
    print("üß™ OpenAI RL Chatbot Test")
    print("=" * 30)
    
    # Test OpenAI connection first
    if not test_openai_connection():
        return
    
    # Test RL Chatbot
    try:
        test_rl_chatbot()
        print("\n‚úÖ All tests completed successfully!")
        
    except Exception as e:
        print(f"\n‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

