#!/usr/bin/env python3
"""
Demo Script: C·∫£i thi·ªán h√†m _format_memory_context
Minh h·ªça s·ª± kh√°c bi·ªát gi·ªØa phi√™n b·∫£n c≈© v√† m·ªõi
"""

import torch
import numpy as np
from typing import List, Dict, Any

class MockRLChatbotModel:
    """Mock model ƒë·ªÉ demo _format_memory_context improvements"""
    
    def __init__(self):
        self.memory_dim = 256
        
    def _format_memory_context_old(self, memory_context: torch.Tensor) -> str:
        """Phi√™n b·∫£n c≈© - ch·ªâ tr·∫£ v·ªÅ s·ªë l∆∞·ª£ng memories"""
        if memory_context is None:
            return ""
        
        try:
            if memory_context.dim() == 3:
                batch_size, num_memories, memory_dim = memory_context.shape
                return f"C√≥ {num_memories} memories li√™n quan ƒë∆∞·ª£c t√¨m th·∫•y t·ª´ c√°c cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc."
            elif memory_context.dim() == 2:
                num_memories, memory_dim = memory_context.shape
                return f"C√≥ {num_memories} memories li√™n quan ƒë∆∞·ª£c t√¨m th·∫•y t·ª´ c√°c cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc."
            else:
                return "C√≥ memories li√™n quan ƒë∆∞·ª£c t√¨m th·∫•y t·ª´ c√°c cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc."
        except Exception as e:
            return "C√≥ memories li√™n quan ƒë∆∞·ª£c t√¨m th·∫•y t·ª´ c√°c cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc."
    
    def _format_memory_context_new(self, memory_context: torch.Tensor, retrieved_info: List[Dict] = None) -> str:
        """Phi√™n b·∫£n m·ªõi - cung c·∫•p th√¥ng tin chi ti·∫øt"""
        if memory_context is None:
            return ""
        
        try:
            # Validate tensor shape and dimensions
            num_memories = 0
            memory_dim = 0
            
            if memory_context.dim() == 3:
                batch_size, num_memories, memory_dim = memory_context.shape
            elif memory_context.dim() == 2:
                num_memories, memory_dim = memory_context.shape
            else:
                return "C√≥ th√¥ng tin memory li√™n quan t·ª´ c√°c cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc."
            
            if num_memories == 0:
                return ""
                
            # Kh·ªüi t·∫°o th√¥ng tin c∆° b·∫£n
            context_parts = [f"üìö T√¨m th·∫•y {num_memories} memories li√™n quan t·ª´ {memory_dim}D memory space."]
            
            # N·∫øu c√≥ retrieved_info, th√™m th√¥ng tin chi ti·∫øt
            if retrieved_info and len(retrieved_info) > 0:
                # Ph√¢n t√≠ch th√¥ng tin memories
                total_similarity = 0
                total_importance = 0
                total_usage = 0
                high_quality_memories = 0
                
                memory_details = []
                
                for i, info in enumerate(retrieved_info[:3]):  # Top 3 memories
                    if isinstance(info, dict):
                        similarity = info.get('similarity', 0)
                        importance = info.get('importance_weight', 1.0)
                        usage = info.get('usage_count', 0)
                        
                        total_similarity += similarity
                        total_importance += importance
                        total_usage += usage
                        
                        # ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng memory
                        if similarity > 0.7 and importance > 1.2:
                            high_quality_memories += 1
                        
                        # Format th√¥ng tin memory
                        quality_indicator = "üî•" if similarity > 0.8 else "‚≠ê" if similarity > 0.6 else "üí°"
                        memory_details.append(
                            f"  {quality_indicator} Memory #{i+1}: "
                            f"ƒë·ªô li√™n quan {similarity:.1%}, "
                            f"quan tr·ªçng {importance:.1f}x, "
                            f"ƒë√£ d√πng {usage} l·∫ßn"
                        )
                
                # T√≠nh to√°n th·ªëng k√™ t·ªïng th·ªÉ
                if num_memories > 0:
                    avg_similarity = total_similarity / min(len(retrieved_info), num_memories)
                    avg_importance = total_importance / min(len(retrieved_info), num_memories)
                    avg_usage = total_usage / min(len(retrieved_info), num_memories)
                    
                    # Th√™m th√¥ng tin ch·∫•t l∆∞·ª£ng t·ªïng th·ªÉ
                    quality_summary = f"üìä Ch·∫•t l∆∞·ª£ng memories: ƒë·ªô li√™n quan trung b√¨nh {avg_similarity:.1%}"
                    
                    if high_quality_memories > 0:
                        quality_summary += f", c√≥ {high_quality_memories} memories ch·∫•t l∆∞·ª£ng cao"
                    
                    if avg_importance > 1.3:
                        quality_summary += f", m·ª©c ƒë·ªô quan tr·ªçng cao ({avg_importance:.1f}x)"
                    elif avg_importance < 0.8:
                        quality_summary += f", m·ª©c ƒë·ªô quan tr·ªçng th·∫•p ({avg_importance:.1f}x)"
                    
                    if avg_usage > 5:
                        quality_summary += f", ƒë∆∞·ª£c s·ª≠ d·ª•ng th∆∞·ªùng xuy√™n ({avg_usage:.0f} l·∫ßn TB)"
                    
                    context_parts.append(quality_summary)
                
                # Th√™m chi ti·∫øt memories
                if memory_details:
                    context_parts.extend(memory_details)
                
                # Ph√¢n t√≠ch utilization v√† fragmentation
                memory_utilization = min(len(retrieved_info), num_memories) / max(num_memories, 1)
                if memory_utilization < 0.5:
                    context_parts.append(f"‚ö†Ô∏è  Memory utilization th·∫•p: {memory_utilization:.1%}")
                
                # ƒê√°nh gi√° hi·ªáu qu·∫£ memory
                if avg_similarity > 0.8 and high_quality_memories >= 2:
                    context_parts.append("‚úÖ Memory system ho·∫°t ƒë·ªông hi·ªáu qu·∫£ v·ªõi memories ch·∫•t l∆∞·ª£ng cao")
                elif avg_similarity < 0.4:
                    context_parts.append("‚ö†Ô∏è  C·∫ßn c·∫£i thi·ªán: memories c√≥ ƒë·ªô li√™n quan th·∫•p")
                
            else:
                # Th√¥ng tin c∆° b·∫£n khi kh√¥ng c√≥ retrieved_info
                estimated_utilization = min(num_memories / 100.0, 1.0)  # Gi·∫£ s·ª≠ max 100 memories
                context_parts.append(f"üìà Estimated memory utilization: {estimated_utilization:.1%}")
                
                if memory_dim != self.memory_dim:
                    context_parts.append(f"‚ö†Ô∏è  Memory dimension mismatch: expected {self.memory_dim}D, got {memory_dim}D")
            
            return "\n".join(context_parts)
                
        except Exception as e:
            return f"C√≥ {getattr(memory_context, 'size', lambda: [0])(0) if hasattr(memory_context, 'size') else 'm·ªôt s·ªë'} memories li√™n quan t·ª´ c√°c cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc."


def create_sample_data():
    """T·∫°o sample data ƒë·ªÉ demo"""
    
    # T·∫°o memory context tensor
    memory_context = torch.randn(1, 4, 256)  # 4 memories, 256 dimensions
    
    # T·∫°o retrieved_info v·ªõi th√¥ng tin chi ti·∫øt
    retrieved_info = [
        {
            "index": 0,
            "similarity": 0.85,
            "importance_weight": 1.5,
            "usage_count": 3
        },
        {
            "index": 1,
            "similarity": 0.72,
            "importance_weight": 1.8,
            "usage_count": 7
        },
        {
            "index": 2,
            "similarity": 0.45,
            "importance_weight": 0.9,
            "usage_count": 1
        },
        {
            "index": 3,
            "similarity": 0.91,
            "importance_weight": 2.0,
            "usage_count": 12
        }
    ]
    
    return memory_context, retrieved_info


def main():
    """Ch·∫°y demo comparison"""
    
    print("=" * 80)
    print("DEMO: C·∫£i thi·ªán h√†m _format_memory_context")
    print("=" * 80)
    
    # Kh·ªüi t·∫°o mock model
    model = MockRLChatbotModel()
    
    # T·∫°o sample data
    memory_context, retrieved_info = create_sample_data()
    
    print("\nüìä Sample Data:")
    print(f"Memory context shape: {memory_context.shape}")
    print(f"Retrieved info: {len(retrieved_info)} memories")
    for i, info in enumerate(retrieved_info):
        print(f"  Memory {i+1}: similarity={info['similarity']:.2f}, "
              f"importance={info['importance_weight']:.1f}x, "
              f"usage={info['usage_count']} l·∫ßn")
    
    print("\n" + "="*50)
    print("üî¥ PHI√äN B·∫¢N C≈®:")
    print("="*50)
    old_result = model._format_memory_context_old(memory_context)
    print(old_result)
    
    print("\n" + "="*50)
    print("üü¢ PHI√äN B·∫¢N M·ªöI:")
    print("="*50)
    new_result = model._format_memory_context_new(memory_context, retrieved_info)
    print(new_result)
    
    print("\n" + "="*80)
    print("üìà PH√ÇN T√çCH S·ª∞ KH√ÅC BI·ªÜT:")
    print("="*80)
    
    print("üî¥ Phi√™n b·∫£n c≈©:")
    print("  ‚ùå Ch·ªâ cung c·∫•p s·ªë l∆∞·ª£ng memories")
    print("  ‚ùå Kh√¥ng c√≥ th√¥ng tin v·ªÅ ch·∫•t l∆∞·ª£ng")
    print("  ‚ùå Kh√¥ng c√≥ th√¥ng tin v·ªÅ utilization")
    print("  ‚ùå Kh√¥ng h·ªó tr·ª£ debugging v√† optimization")
    
    print("\nüü¢ Phi√™n b·∫£n m·ªõi:")
    print("  ‚úÖ Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ t·ª´ng memory")
    print("  ‚úÖ Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng v√† ƒë·ªô li√™n quan")
    print("  ‚úÖ Hi·ªÉn th·ªã usage patterns v√† importance weights")
    print("  ‚úÖ ƒê√°nh gi√° memory utilization v√† fragmentation")
    print("  ‚úÖ C·∫£nh b√°o v·∫•n ƒë·ªÅ v√† g·ª£i √Ω c·∫£i thi·ªán")
    print("  ‚úÖ H·ªó tr·ª£ debugging v√† performance monitoring")
    
    print("\nüìù K·∫æT LU·∫¨N:")
    print("Phi√™n b·∫£n m·ªõi cung c·∫•p c√°i nh√¨n to√†n di·ªán v·ªÅ memory system,")
    print("gi√∫p ch·∫©n ƒëo√°n hi·ªáu qu·∫£ v√† t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t chatbot.")
    
    print("\n" + "="*80)


if __name__ == "__main__":
    main()
