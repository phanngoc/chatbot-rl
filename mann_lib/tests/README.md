# MANN Tests Directory

This directory contains individual test cases for the Memory-Augmented Neural Network (MANN) system, organized for clear understanding of the training flow and system components.

## Test Structure

### ğŸ—ï¸ Core Components Tests
- **`test_basic_conversation.py`** - Tests basic chatbot conversation flow
- **`test_memory_search.py`** - Tests embedding-based memory search with fallback
- **`test_memory_management.py`** - Tests memory capacity management and cleanup
- **`test_external_working_memory.py`** - Tests external working memory operations

### ğŸ¯ PPO Training Tests  
- **`test_ppo_training.py`** - Comprehensive PPO training with CSV data loading
- **`test_ppo_importance_ratio.py`** - Tests PPO mathematical components and clipping

### ğŸ”§ System Tests
- **`test_health_monitoring.py`** - Tests health monitoring and performance metrics
- **`test_api_integration.py`** - Tests API client functionality

### ğŸ“Š Data Files (`data/`)
- **`ppo_training_data.csv`** - Training questions, answers, and metadata (30 samples)
- **`memory_bank_data.csv`** - Memory initialization data with comprehensive AI/ML content

## Memory Search Functionality

The system now includes **intelligent fallback** for memory search:

### ğŸ”„ OpenAI Embeddings (Primary)
- Uses `text-embedding-3-small` model for semantic similarity
- Requires `OPENAI_API_KEY` environment variable
- Provides high-quality semantic matching

### ğŸ›¡ï¸ Fallback System (Backup)  
- **Hash-based vectorization** when OpenAI API is unavailable
- Maintains same interface and functionality
- Uses simple word hashing for similarity calculation
- **Zero breaking** - tests continue to work without API key

## PPO Training Flow

The PPO training test demonstrates the complete training pipeline:

```
1ï¸âƒ£  Initialize MANN model with external working memory
     â†“
2ï¸âƒ£  Load memory bank data from CSV (30 diverse AI/ML memories)
     â†“  
3ï¸âƒ£  Load training questions and reference answers from CSV
     â†“
4ï¸âƒ£  Forward pass: generate answers with current policy
     â†“
5ï¸âƒ£  Compute rewards by comparing generated vs reference answers
     â†“
6ï¸âƒ£  Compute advantages and returns for PPO
     â†“
7ï¸âƒ£  Update policy using PPO loss (clipped importance ratio)
     â†“
8ï¸âƒ£  Test improved policy and measure performance gain
```

## Running Tests

### Individual Tests (No API Key Required)
```bash
cd mann_lib/tests

# Core functionality tests
python test_basic_conversation.py
python test_memory_search.py          # Works with/without OPENAI_API_KEY
python test_memory_management.py
python test_external_working_memory.py

# PPO training tests
python test_ppo_training.py           # Enhanced with CSV data
python test_ppo_importance_ratio.py

# System tests  
python test_health_monitoring.py
python test_api_integration.py        # Requires API server running
```

### Complete Test Suite
```bash
cd mann_lib/tests
python run_all_tests.py              # Runs all 8 tests with reporting
```

### With OpenAI API (Enhanced)
```bash
export OPENAI_API_KEY="your-api-key-here"
cd mann_lib/tests
python test_memory_search.py         # Uses OpenAI embeddings
```

## Key Features

### ğŸ” Intelligent Memory Search
- **Primary**: OpenAI embeddings for semantic similarity
- **Fallback**: Hash-based vectorization when API unavailable
- **Same interface**: `search_memories(query, top_k, min_similarity)`
- **Graceful degradation**: No breaking changes

### ğŸ“Š Comprehensive Data Loading
- CSV-based training data with categories and difficulty levels
- Memory bank initialization with importance weights
- Structured test data for consistent evaluation

### ğŸ› Debug Logging
PPO training generates detailed debug logs (`debug_reward_process.log`) containing:
- Input questions, generated answers, reference answers
- Reward computation details and statistics
- Advantage and return calculations
- Training progress information

### ğŸ“ˆ Performance Tracking
- Pre/post-training reward comparison
- Memory utilization statistics
- Training improvement percentages
- Model parameter counts

## Understanding Training Flow

### Memory Operations
- **Write**: `Î¼Ì‡áµ¢ = -záµ¢Î¼áµ¢ + cwzáµ¢a + záµ¢Å´qÎ¼áµ€`
- **Read**: `Mr = Î¼z, z = softmax(Î¼áµ€q)`  
- **Output**: `uad = -Å´áµ€(Ïƒ(VÌ‚áµ€xÌƒ + bÌ‚v) + Mr) - bÌ‚w`

### PPO Mathematics
- **Importance Ratio**: `r(Î¸) = Ï€_Î¸(a|s) / Ï€_Î¸_old(a|s)`
- **Advantage**: `A = Q(s,a) - V(s)`
- **PPO Loss**: `L = min(r(Î¸)Â·A, clip(r(Î¸), 1-Îµ, 1+Îµ)Â·A)`

## Data Format

### Training Data CSV
```csv
question,reference_answer,category,difficulty,importance_weight
"Python cÃ³ Æ°u Ä‘iá»ƒm gÃ¬?","Python lÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh cao cáº¥p...",programming,1,1.0
```

### Memory Bank CSV  
```csv
content,context,tags,importance_weight
"Python lÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh...","programming_context","python,programming",1.2
```

## Troubleshooting

### OpenAI API Issues
- **No API Key**: Tests use fallback system automatically
- **API Errors**: System gracefully degrades to hash-based similarity
- **Rate Limits**: Fallback handles temporary API failures

### Test Failures
- **Check Dependencies**: Ensure `torch`, `numpy`, `openai` installed
- **API Server**: `test_api_integration.py` requires `python run_api.py`
- **Memory Limits**: Some tests use reduced memory sizes for faster execution

## Debug Output

The PPO training test produces:
- ğŸ“„ **Debug logs**: Detailed reward process information
- ğŸ“Š **Performance metrics**: Training improvement statistics  
- ğŸ§  **Memory stats**: Utilization and operation counts
- ğŸ¯ **Sample outputs**: Before/after training comparisons

This structure provides **robust, fault-tolerant testing** with **clear insight** into the MANN system's training process and helps debug reward computation issues **without requiring external API dependencies**.