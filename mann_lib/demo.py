#!/usr/bin/env python3
"""
Demo script cho MANN CLI Chatbot
Th·ªÉ hi·ªán c√°c t√≠nh nƒÉng ch√≠nh c·ªßa h·ªá th·ªëng
"""

import asyncio
import sys
import time
from pathlib import Path

# Add current directory to path
sys.path.insert(0, str(Path(__file__).parent))

from mann_chatbot import MANNChatbot
from standalone_mann.mann_config import MANNConfig


async def demo_basic_conversation():
    """Demo cu·ªôc tr√≤ chuy·ªán c∆° b·∫£n"""
    print("üé≠ Demo: Basic Conversation")
    print("=" * 50)
    
    config = MANNConfig()
    chatbot = MANNChatbot(config)
    
    try:
        await chatbot.initialize()
        
        # Simulate conversation
        conversations = [
            "Xin ch√†o, t√¥i t√™n l√† Ng·ªçc",
            "T√¥i 25 tu·ªïi v√† ƒëang l√†m vi·ªác t·∫°i H√† N·ªôi",
            "T√¥i th√≠ch l·∫≠p tr√¨nh Python v√† h·ªçc v·ªÅ AI",
            "B·∫°n c√≥ nh·ªõ t√™n t√¥i kh√¥ng?",
            "T√¥i ƒëang h·ªçc v·ªÅ Machine Learning",
            "B·∫°n bi·∫øt g√¨ v·ªÅ s·ªü th√≠ch c·ªßa t√¥i?",
            "T√¥i mu·ªën t·∫°o m·ªôt chatbot th√¥ng minh",
            "H√¥m nay tr·ªùi ƒë·∫πp, t√¥i ƒëi d·∫°o c√¥ng vi√™n"
        ]
        
        for i, user_input in enumerate(conversations, 1):
            print(f"\nüë§ User {i}: {user_input}")
            
            start_time = time.time()
            response = await chatbot.process_user_input(user_input)
            processing_time = time.time() - start_time
            
            print(f"ü§ñ Bot: {response}")
            print(f"‚è±Ô∏è  Processing time: {processing_time:.3f}s")
            
            # Small delay for demo effect
            await asyncio.sleep(1)
        
        # Show statistics
        stats = await chatbot.get_memory_statistics()
        print(f"\nüìä Session Statistics:")
        print(f"  Total queries: {stats.get('total_queries', 0)}")
        print(f"  Memories created: {stats.get('total_memories_created', 0)}")
        print(f"  Memory utilization: {stats.get('memory_utilization', 0):.2%}")
        print(f"  Total retrievals: {stats.get('total_retrievals', 0)}")
        print(f"  Total writes: {stats.get('total_writes', 0)}")
        print(f"  Memory matrix norm: {stats.get('memory_matrix_norm', 0):.4f}")
        print(f"  WÃÇ norm: {stats.get('W_hat_norm', 0):.4f}")
        print(f"  VÃÇ norm: {stats.get('V_hat_norm', 0):.4f}")
        
    finally:
        await chatbot.shutdown()


async def demo_memory_search():
    """Demo t√¨m ki·∫øm memory"""
    print("\nüîç Demo: Memory Search")
    print("=" * 50)
    
    config = MANNConfig()
    chatbot = MANNChatbot(config)
    
    try:
        await chatbot.initialize()
        
        # Add some test memories first
        test_memories = [
            "T√¥i t√™n l√† Ng·ªçc, 25 tu·ªïi",
            "T√¥i th√≠ch l·∫≠p tr√¨nh Python v√† JavaScript",
            "T√¥i ƒëang h·ªçc v·ªÅ AI v√† Machine Learning",
            "T√¥i s·ªëng ·ªü H√† N·ªôi v√† l√†m vi·ªác t·∫°i c√¥ng ty ABC",
            "T√¥i th√≠ch ƒë·ªçc s√°ch v√† ch∆°i game",
            "T√¥i mu·ªën tr·ªü th√†nh m·ªôt AI Engineer",
            "H√¥m nay t√¥i ƒëi mua s·∫Øm ·ªü trung t√¢m th∆∞∆°ng m·∫°i",
            "T√¥i c√≥ m·ªôt con m√®o t√™n l√† Mimi"
        ]
        
        print("üìù Adding test memories...")
        for memory in test_memories:
            await chatbot.process_user_input(memory)
            await asyncio.sleep(0.5)
        
        # Search for different topics
        search_queries = [
            "t√™n",
            "l·∫≠p tr√¨nh",
            "AI",
            "H√† N·ªôi",
            "m√®o",
            "s·ªü th√≠ch"
        ]
        
        print("\nüîç Searching memories...")
        for query in search_queries:
            print(f"\nQuery: '{query}'")
            results = await chatbot.search_memories(query, top_k=3)
            
            if results:
                print(f"  Found {len(results)} memories:")
                for i, result in enumerate(results, 1):
                    print(f"    {i}. {result['content'][:60]}...")
                    print(f"       Similarity: {result.get('similarity', 0):.3f}")
                    print(f"       Importance: {result.get('importance_weight', 0):.2f}")
            else:
                print("  No memories found.")
    
    finally:
        await chatbot.shutdown()


async def demo_memory_management():
    """Demo qu·∫£n l√Ω memory"""
    print("\nüíæ Demo: Memory Management")
    print("=" * 50)
    
    config = MANNConfig()
    config.memory_size = 10  # Small size for demo
    chatbot = MANNChatbot(config)
    
    try:
        await chatbot.initialize()
        
        # Add memories until capacity is reached
        print("üìù Adding memories to test capacity management...")
        
        for i in range(15):  # More than memory_size
            memory_content = f"Memory {i+1}: This is test memory number {i+1}"
            await chatbot.process_user_input(memory_content)
            await asyncio.sleep(0.1)
        
        # Show memory statistics
        stats = await chatbot.get_memory_statistics()
        print(f"\nüìä Memory Statistics:")
        print(f"  Total memories: {stats.get('total_memories', 0)}")
        print(f"  Memory utilization: {stats.get('memory_utilization', 0):.2%}")
        print(f"  Max capacity: {config.memory_size}")
        
        # Show memory contents
        print(f"\nüìã Current Memories:")
        for i, memory in enumerate(chatbot.mann_model.memory_bank, 1):
            print(f"  {i}. {memory.content[:50]}...")
            print(f"     Importance: {memory.importance_weight:.2f}")
            print(f"     Usage count: {memory.usage_count}")
    
    finally:
        await chatbot.shutdown()


async def demo_health_monitoring():
    """Demo health monitoring"""
    print("\nüè• Demo: Health Monitoring")
    print("=" * 50)
    
    config = MANNConfig()
    config.enable_monitoring = True
    chatbot = MANNChatbot(config)
    
    try:
        await chatbot.initialize()
        
        # Perform some operations
        print("üîÑ Performing operations to generate metrics...")
        
        for i in range(5):
            await chatbot.process_user_input(f"Test operation {i+1}")
            await asyncio.sleep(0.5)
        
        # Check health
        print("\nüè• Health Check:")
        health = await chatbot.health_check()
        print(f"  Status: {health.get('status', 'unknown')}")
        
        checks = health.get('checks', {})
        for check_name, check_data in checks.items():
            status = check_data.get('status', 'unknown')
            status_emoji = "‚úÖ" if status == "healthy" else "‚ùå"
            print(f"  {status_emoji} {check_name}: {status}")
        
        # Show performance stats
        if chatbot.monitor:
            perf_stats = chatbot.monitor.get_performance_stats()
            print(f"\nüìà Performance Statistics:")
            print(f"  Total queries: {perf_stats.get('total_queries', 0)}")
            print(f"  Average processing time: {perf_stats.get('avg_processing_time', 0):.3f}s")
            print(f"  Error rate: {perf_stats.get('error_rate', 0):.2%}")
            print(f"  Memory utilization: {perf_stats.get('memory_utilization', 0):.2%}")
    
    finally:
        await chatbot.shutdown()


async def demo_external_working_memory():
    """Demo External Working Memory features"""
    print("\nüß† Demo: External Working Memory")
    print("=" * 50)
    
    config = MANNConfig()
    chatbot = MANNChatbot(config)
    
    try:
        await chatbot.initialize()
        
        print("üî¨ Testing External Working Memory Operations...")
        
        # Test sequences to demonstrate learning
        test_sequences = [
            "T√¥i t√™n l√† Ng·ªçc v√† th√≠ch l·∫≠p tr√¨nh",
            "T√¥i ƒëang h·ªçc v·ªÅ AI v√† Machine Learning", 
            "T√¥i s·ªëng ·ªü H√† N·ªôi v√† l√†m vi·ªác t·∫°i ABC",
            "T√¥i c√≥ s·ªü th√≠ch ƒë·ªçc s√°ch v√† ch∆°i game",
            "T√¥i mu·ªën tr·ªü th√†nh AI Engineer"
        ]
        
        print("\nüìù Processing test sequences...")
        for i, sequence in enumerate(test_sequences, 1):
            print(f"\nüë§ Input {i}: {sequence}")
            
            start_time = time.time()
            response = await chatbot.process_user_input(sequence)
            processing_time = time.time() - start_time
            
            print(f"ü§ñ Response: {response}")
            print(f"‚è±Ô∏è  Processing time: {processing_time:.3f}s")
            
            # Show memory statistics after each input
            stats = await chatbot.get_memory_statistics()
            print(f"üìä Memory stats: retrievals={stats.get('total_retrievals', 0)}, writes={stats.get('total_writes', 0)}")
            
            await asyncio.sleep(0.5)
        
        # Test memory search
        print("\nüîç Testing Memory Search...")
        search_queries = ["t√™n", "l·∫≠p tr√¨nh", "AI", "H√† N·ªôi", "s·ªü th√≠ch"]
        
        for query in search_queries:
            print(f"\nüîç Searching for: '{query}'")
            results = await chatbot.search_memories(query, top_k=2)
            
            if results:
                print(f"  Found {len(results)} relevant memories:")
                for j, result in enumerate(results, 1):
                    print(f"    {j}. {result['content'][:60]}...")
                    print(f"       Similarity: {result.get('similarity', 0):.3f}")
            else:
                print("  No relevant memories found.")
        
        # Show final statistics
        final_stats = await chatbot.get_memory_statistics()
        print(f"\nüìä Final External Working Memory Statistics:")
        print(f"  Total queries: {final_stats.get('total_queries', 0)}")
        print(f"  Total retrievals: {final_stats.get('total_retrievals', 0)}")
        print(f"  Total writes: {final_stats.get('total_writes', 0)}")
        print(f"  Memory matrix norm: {final_stats.get('memory_matrix_norm', 0):.4f}")
        print(f"  WÃÇ matrix norm: {final_stats.get('W_hat_norm', 0):.4f}")
        print(f"  VÃÇ matrix norm: {final_stats.get('V_hat_norm', 0):.4f}")
        print(f"  Memory utilization: {final_stats.get('memory_utilization', 0):.2%}")
        
        print(f"\n‚úÖ External Working Memory Demo Complete!")
        print(f"   - Memory Write: ŒºÃá·µ¢ = -z·µ¢Œº·µ¢ + cwz·µ¢a + z·µ¢WÃÇqŒº·µÄ")
        print(f"   - Memory Read: Mr = Œºz, z = softmax(Œº·µÄq)")
        print(f"   - NN Output: uad = -WÃÇ·µÄ(œÉ(VÃÇ·µÄxÃÉ + bÃÇv) + Mr) - bÃÇw")
        
    finally:
        await chatbot.shutdown()


async def demo_ppo_training():
    """Demo PPO training with memory-augmented network"""
    print("\nüéØ Demo: PPO Training with Memory")
    print("=" * 50)
    
    import torch
    import numpy as np
    import os
    from standalone_mann.mann_core import MemoryAugmentedNetwork
    
    # Clear any existing debug log
    debug_log_path = "debug_reward_process.log"
    if os.path.exists(debug_log_path):
        os.remove(debug_log_path)
        print(f"üóëÔ∏è  Cleared existing debug log: {debug_log_path}")
    
    # Create a simple MANN model for testing
    print("üß† Initializing MANN model for PPO training...")
    
    # Model configuration
    input_size = 64
    hidden_size = 128
    memory_size = 20  # Reduced for cleaner debugging
    memory_dim = 64
    output_size = 1000  # Vocabulary size
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"  Using device: {device}")
    
    try:
        # Initialize model
        mann_model = MemoryAugmentedNetwork(
            input_size=input_size,
            hidden_size=hidden_size, 
            memory_size=memory_size,
            memory_dim=memory_dim,
            output_size=output_size,
            device=device
        ).to(device)
        
        print(f"  Model initialized with {sum(p.numel() for p in mann_model.parameters())} parameters")
        
        # Clear any existing memory bank
        mann_model.memory_bank = []
        print("  Cleared existing memory bank")
        
        # Add comprehensive test memories for better debugging
        print("\nüìù Adding comprehensive test memories...")
        test_memories = [
            # Programming concepts
            ("Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh cao c·∫•p, d·ªÖ h·ªçc v√† m·∫°nh m·∫Ω", "programming_context", ["python", "programming", "language"]),
            ("JavaScript l√† ng√¥n ng·ªØ web ph·ªï bi·∫øn cho frontend v√† backend", "web_context", ["javascript", "web", "frontend"]),
            ("Java l√† ng√¥n ng·ªØ h∆∞·ªõng ƒë·ªëi t∆∞·ª£ng m·∫°nh m·∫Ω cho enterprise", "enterprise_context", ["java", "oop", "enterprise"]),
            
            # AI/ML concepts
            ("Machine Learning l√† nh√°nh c·ªßa AI s·ª≠ d·ª•ng d·ªØ li·ªáu ƒë·ªÉ h·ªçc", "ml_context", ["ml", "ai", "data"]),
            ("Deep Learning s·ª≠ d·ª•ng neural network nhi·ªÅu l·ªõp", "dl_context", ["deep_learning", "neural_network"]),
            ("Natural Language Processing x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n", "nlp_context", ["nlp", "language", "processing"]),
            
            # Frameworks
            ("PyTorch l√† framework deep learning linh ho·∫°t c·ªßa Facebook", "framework_context", ["pytorch", "deep_learning", "facebook"]),
            ("TensorFlow l√† platform ML m·ªü c·ªßa Google", "tf_context", ["tensorflow", "ml", "google"]),
            ("Scikit-learn l√† th∆∞ vi·ªán ML c∆° b·∫£n cho Python", "sklearn_context", ["sklearn", "ml", "python"]),
            
            # Algorithms
            ("Reinforcement Learning h·ªçc th√¥ng qua reward v√† punishment", "rl_context", ["rl", "reward", "learning"]),
            ("PPO l√† thu·∫≠t to√°n policy optimization ·ªïn ƒë·ªãnh", "ppo_context", ["ppo", "optimization", "policy"]),
            ("Q-Learning h·ªçc value function th√¥ng qua exploration", "qlearning_context", ["qlearning", "value", "exploration"])
        ]
        
        for i, (content, context, tags) in enumerate(test_memories):
            memory_id = mann_model.add_memory(content, context, tags, importance_weight=1.0 + i*0.1)
            print(f"  [{i+1:2d}] Added: {memory_id[:8]}... - {content[:40]}...")
        
        # Generate comprehensive training data
        print("\nüé≤ Generating comprehensive training data...")
        questions = [
            "Python c√≥ ∆∞u ƒëi·ªÉm g√¨?",
            "Machine Learning ho·∫°t ƒë·ªông nh∆∞ th·∫ø nao?", 
            "PyTorch kh√°c TensorFlow nh∆∞ th·∫ø n√†o?",
            "Reinforcement Learning l√† g√¨?",
            "PPO algorithm c√≥ g√¨ ƒë·∫∑c bi·ªát?",
            "Deep Learning v√† Machine Learning kh√°c nhau ra sao?",
            "JavaScript d√πng ƒë·ªÉ l√†m g√¨?",
            "Natural Language Processing gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ g√¨?"
        ]
        
        reference_answers = [
            "Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh cao c·∫•p, d·ªÖ h·ªçc v√† m·∫°nh m·∫Ω",
            "Machine Learning l√† nh√°nh c·ªßa AI s·ª≠ d·ª•ng d·ªØ li·ªáu ƒë·ªÉ h·ªçc",
            "PyTorch l√† framework deep learning linh ho·∫°t c·ªßa Facebook", 
            "Reinforcement Learning h·ªçc th√¥ng qua reward v√† punishment",
            "PPO l√† thu·∫≠t to√°n policy optimization ·ªïn ƒë·ªãnh",
            "Deep Learning s·ª≠ d·ª•ng neural network nhi·ªÅu l·ªõp",
            "JavaScript l√† ng√¥n ng·ªØ web ph·ªï bi·∫øn cho frontend v√† backend",
            "Natural Language Processing x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n"
        ]
        
        # Create input tensors
        batch_size = len(questions)
        seq_len = 10
        input_tensors = torch.randn(batch_size, seq_len, input_size, device=device)
        
        print(f"  Created {batch_size} training samples")
        
        # Test PPO forward pass
        print("\nüîÑ Testing PPO forward pass...")
        forward_results = mann_model.ppo_forward_with_memory(
            input_tensors, questions, generate_answers=True
        )
        
        print(f"  Forward pass completed:")
        print(f"    Logits shape: {forward_results['logits'].shape}")
        print(f"    Values shape: {forward_results['values'].shape}")
        print(f"    Memory context shape: {forward_results['memory_context'].shape}")
        print(f"    Retrieved memories: {len(forward_results['retrieved_memories'])}")
        
        # Generate answers using current policy (concise output)
        print("\nüéØ Generating answers with current policy...")
        generated_answers = []
        
        for i, question in enumerate(questions):
            answer, memory_info = mann_model.generate_answer_with_ppo(
                question, input_tensors[i], max_length=30  # Shorter for cleaner logs
            )
            generated_answers.append(answer)
            print(f"  [{i+1}] Q: {question[:35]}...")
            print(f"      A: {answer[:50]}...")
            print(f"      Memories: {len(memory_info)}")
        
        # Test reward computation
        print("\nüèÜ Computing answer rewards...")
        rewards = mann_model.compute_answer_rewards(
            generated_answers, reference_answers, questions
        )
        reward_stats = {
            'values': rewards.numpy().tolist(),
            'mean': rewards.mean().item(),
            'std': rewards.std().item(),
            'min': rewards.min().item(),
            'max': rewards.max().item()
        }
        print(f"  Rewards: {[f'{r:.3f}' for r in reward_stats['values']]}")
        print(f"  Stats: mean={reward_stats['mean']:.3f}, std={reward_stats['std']:.3f}")
        
        # Perform PPO training step with detailed debugging
        print(f"\nüöÄ Performing PPO training step (epochs=2, lr=3e-4)...")
        print(f"   üìä Check '{debug_log_path}' for detailed reward process debugging")
        
        training_stats = mann_model.ppo_update(
            questions=questions,
            generated_answers=generated_answers,
            reference_answers=reference_answers,
            input_tensors=input_tensors,
            learning_rate=3e-4,
            epochs=2  # Reduced for demo
        )
        
        print(f"  ‚úÖ Training completed:")
        print(f"    üìâ Loss: {training_stats['avg_loss']:.4f}")
        print(f"    üèÜ Reward: {training_stats['avg_reward']:.4f}")
        print(f"    üìà Advantage: {training_stats['avg_advantage']:.4f}")
        print(f"    üîÄ Entropy: {training_stats['policy_entropy']:.4f}")
        print(f"    ‚öñÔ∏è  Importance ratio: {training_stats['importance_ratio']:.4f}")
        print(f"    üíæ Memories retrieved: {training_stats['memories_retrieved']}")
        
        # Test after training (concise output)
        print("\nüîÑ Testing policy after training...")
        new_generated_answers = []
        
        print(f"  Post-training answers (first 3 samples):")
        for i, question in enumerate(questions[:3]):  # Show only first 3 for brevity
            answer, memory_info = mann_model.generate_answer_with_ppo(
                question, input_tensors[i], max_length=30
            )
            new_generated_answers.append(answer)
            print(f"    [{i+1}] Q: {question[:30]}...")
            print(f"        A: {answer[:40]}...")
        
        # Generate all new answers for comparison
        for i, question in enumerate(questions[3:], 3):  # Complete remaining answers
            answer, memory_info = mann_model.generate_answer_with_ppo(
                question, input_tensors[i], max_length=30
            )
            new_generated_answers.append(answer)
        
        # Compare rewards
        new_rewards = mann_model.compute_answer_rewards(
            new_generated_answers, reference_answers, questions
        )
        
        print(f"\nüìä Training Results Summary:")
        print(f"  üéØ Pre-training  reward: {rewards.mean().item():.3f} (std: {rewards.std().item():.3f})")
        print(f"  üéØ Post-training reward: {new_rewards.mean().item():.3f} (std: {new_rewards.std().item():.3f})")
        improvement = (new_rewards.mean() - rewards.mean()).item()
        improvement_emoji = "üìà" if improvement > 0 else "üìâ" if improvement < 0 else "‚û°Ô∏è"
        print(f"  {improvement_emoji} Improvement: {improvement:+.3f}")
        
        # Show compact memory statistics
        stats = mann_model.get_memory_statistics()
        print(f"\nüíæ Final Memory Stats:")
        print(f"  üìù Memories: {stats['total_memories']} | Utilization: {stats['memory_utilization']:.1%}")
        print(f"  üîç Retrievals: {stats['total_retrievals']} | Writes: {stats['total_writes']}")
        print(f"  üß† Matrix norm: {stats['memory_matrix_norm']:.4f}")
        
        print(f"\n‚úÖ PPO Training Demo Complete!")
        print(f"   üìÑ Debug details saved to: {debug_log_path}")
        print(f"   üìä Review the debug log to analyze reward computation process")
        
    except Exception as e:
        print(f"‚ùå PPO training demo failed: {e}")
        import traceback
        traceback.print_exc()


async def demo_ppo_importance_ratio():
    """Demo PPO importance ratio calculation"""
    print("\n‚öñÔ∏è Demo: PPO Importance Ratio Calculation")
    print("=" * 50)
    
    import torch
    from standalone_mann.mann_core import MemoryAugmentedNetwork
    
    print("üßÆ Testing PPO importance ratio computation...")
    
    # Small model for testing
    mann_model = MemoryAugmentedNetwork(
        input_size=32,
        hidden_size=64, 
        memory_size=10,
        memory_dim=32,
        output_size=100
    )
    
    try:
        # Create test data
        hidden_state = torch.randn(64)  # hidden_size
        memory_context = torch.randn(32)  # memory_dim
        actions = torch.randint(0, 100, (5,))  # 5 action tokens
        
        print(f"  Hidden state shape: {hidden_state.shape}")
        print(f"  Memory context shape: {memory_context.shape}")
        print(f"  Actions: {actions.numpy()}")
        
        # Test importance ratio calculation
        importance_ratio = mann_model.memory_interface.compute_ppo_importance_ratio(
            hidden_state, memory_context, actions
        )
        
        print(f"  Importance ratios: {importance_ratio.detach().numpy()}")
        print(f"  Average importance ratio: {importance_ratio.mean().item():.3f}")
        print(f"  Min ratio: {importance_ratio.min().item():.3f}")
        print(f"  Max ratio: {importance_ratio.max().item():.3f}")
        
        # Test advantage computation
        rewards = torch.tensor([0.8, 0.9, 0.7, 0.6, 0.85])
        values = torch.tensor([0.5, 0.6, 0.4, 0.3, 0.55])
        
        advantages, returns = mann_model.memory_interface.compute_advantages(rewards, values)
        
        print(f"\nüìà Advantage Computation:")
        print(f"  Rewards: {rewards.numpy()}")
        print(f"  Values: {values.numpy()}")
        print(f"  Advantages: {advantages.numpy()}")
        print(f"  Returns: {returns.numpy()}")
        
        # Test PPO loss computation
        loss_dict = mann_model.memory_interface.compute_ppo_loss(
            hidden_state, memory_context, actions, advantages, returns
        )
        
        print(f"\nüìâ PPO Loss Components:")
        print(f"  Policy loss: {loss_dict['policy_loss'].item():.4f}")
        print(f"  Value loss: {loss_dict['value_loss'].item():.4f}")
        print(f"  Entropy loss: {loss_dict['entropy_loss'].item():.4f}")
        print(f"  Total loss: {loss_dict['total_loss'].item():.4f}")
        print(f"  Entropy: {loss_dict['entropy'].item():.4f}")
        
        print(f"\n‚úÖ PPO Importance Ratio Demo Complete!")
        
    except Exception as e:
        print(f"‚ùå PPO importance ratio demo failed: {e}")
        import traceback
        traceback.print_exc()


async def demo_api_integration():
    """Demo API integration"""
    print("\nüåê Demo: API Integration")
    print("=" * 50)
    
    from standalone_mann.mann_api import MANNClient
    
    # Note: This demo assumes API server is running
    print("üì° Testing API client (requires running API server)...")
    
    try:
        async with MANNClient("http://localhost:8000") as client:
            # Health check
            print("üè• API Health Check:")
            health = await client.health_check()
            print(f"  Status: {health.get('status', 'unknown')}")
            print(f"  Memory count: {health.get('memory_count', 0)}")
            
            # Add memory via API
            print("\nüìù Adding memory via API:")
            memory_id = await client.add_memory(
                content="API test memory",
                context="api_demo",
                tags=["test", "api"],
                importance_weight=1.5
            )
            print(f"  Added memory: {memory_id}")
            
            # Search via API
            print("\nüîç Searching via API:")
            results = await client.search_memories("test", top_k=3)
            print(f"  Found {len(results)} memories")
            
            # Process query via API
            print("\nüöÄ Processing query via API:")
            response = await client.process_query("Hello from API", retrieve_memories=True)
            print(f"  Response: {response.get('output', 'No output')}")
            print(f"  Processing time: {response.get('processing_time', 0):.3f}s")
            
    except Exception as e:
        print(f"‚ùå API demo failed: {e}")
        print("üí° Make sure API server is running: python run_api.py")


async def main():
    """Run all demos"""
    print("üé™ MANN CLI Chatbot Demo Suite")
    print("=" * 60)
    
    demos = [
        ("Basic Conversation", demo_basic_conversation),
        ("External Working Memory", demo_external_working_memory),
        ("PPO Training", demo_ppo_training),
        ("PPO Importance Ratio", demo_ppo_importance_ratio),
        ("Memory Search", demo_memory_search),
        ("Memory Management", demo_memory_management),
        ("Health Monitoring", demo_health_monitoring),
        ("API Integration", demo_api_integration)
    ]
    
    for demo_name, demo_func in demos:
        try:
            print(f"\nüé¨ Starting: {demo_name}")
            await demo_func()
            print(f"‚úÖ Completed: {demo_name}")
        except Exception as e:
            print(f"‚ùå Failed: {demo_name} - {e}")
        
        print("\n" + "="*60)
        await asyncio.sleep(2)  # Pause between demos
    
    print("\nüéâ All demos completed!")
    print("\nüí° To run individual demos:")
    print("  python demo.py --demo basic")
    print("  python demo.py --demo external") 
    print("  python demo.py --demo ppo")
    print("  python demo.py --demo ppo-ratio")
    print("  python demo.py --demo search")
    print("  python demo.py --demo memory")
    print("  python demo.py --demo health")
    print("  python demo.py --demo api")
    print("\nüß™ Or run organized test suite:")
    print("  cd tests && python run_all_tests.py")
    print("  cd tests && python test_ppo_training.py  # PPO with CSV data")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="MANN CLI Chatbot Demo")
    parser.add_argument("--demo", choices=["basic", "external", "ppo", "ppo-ratio", "search", "memory", "health", "api"], 
                       help="Run specific demo")
    
    args = parser.parse_args()
    
    if args.demo:
        demo_map = {
            "basic": demo_basic_conversation,
            "external": demo_external_working_memory,
            "ppo": demo_ppo_training,
            "ppo-ratio": demo_ppo_importance_ratio,
            "search": demo_memory_search,
            "memory": demo_memory_management,
            "health": demo_health_monitoring,
            "api": demo_api_integration
        }
        
        print(f"üé¨ Running demo: {args.demo}")
        asyncio.run(demo_map[args.demo]())
    else:
        asyncio.run(main())
