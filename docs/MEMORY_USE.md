T√¥i s·∫Ω ph√¢n t√≠ch code v√† t√≥m t·∫Øt c√°ch h·ªá th·ªëng memory ho·∫°t ƒë·ªông b·∫±ng bi·ªÉu ƒë·ªì Mermaid v√† c√¥ng th·ª©c to√°n h·ªçc.

[1 tool called]

D·ª±a tr√™n ph√¢n t√≠ch code, t√¥i s·∫Ω t√≥m t·∫Øt c√°ch memory app ho·∫°t ƒë·ªông:

[3 tools called]

## T√≥m t·∫Øt Memory System - RLChatbot

### üèóÔ∏è **Ki·∫øn tr√∫c t·ªïng th·ªÉ**

H·ªá th·ªëng memory ƒë∆∞·ª£c thi·∫øt k·∫ø theo m√¥ h√¨nh **Intelligent Memory Manager** th·ª±c hi·ªán **Algorithm 1** v·ªõi c√°c th√†nh ph·∫ßn ch√≠nh:

1. **RLChatbotAgent** - Agent ch√≠nh ƒëi·ªÅu ph·ªëi to√†n b·ªô h·ªá th·ªëng
2. **IntelligentMemoryManager** - Core memory management logic
3. **RetrievalAugmentedMemory** - Vector-based memory storage
4. **Knowledge Database** - Structured knowledge storage
5. **Meta-learning System** - Adaptive learning
6. **Temporal Weighting** - Time-based importance scoring

### üìä **C√¥ng th·ª©c to√°n h·ªçc ch√≠nh**

#### **1. Similarity Calculation**
$$
\text{similarity}(q, m) = \frac{q \cdot m}{||q|| \times ||m||}
$$
Trong ƒë√≥:
- $q$ = query embedding vector
- $m$ = memory embedding vector

#### **2. Memory Operation Decision Logic**
$$
\text{Operation} = \begin{cases}
\text{DELETE} & \text{if } \text{sim} \geq \tau_{\text{delete}} \text{ and } I_{\text{new}} \leq I_{\text{existing}} \\
\text{UPDATE} & \text{if } \tau_{\text{update}} \leq \text{sim} < \tau_{\text{delete}} \text{ and } \Delta I > \theta \\
\text{ADD} & \text{if } \text{sim} < \tau_{\text{update}} \text{ and } \text{capacity} < C_{\text{max}} \\
\text{NOOP} & \text{otherwise}
\end{cases}
$$

Trong ƒë√≥:
- $\tau_{\text{delete}} = 0.95$ - Delete threshold
- $\tau_{\text{update}} = 0.8$ - Update threshold  
- $I$ - Importance score
- $\theta = 0.3$ - Importance threshold
- $C_{\text{max}} = 5000$ - Max capacity

#### **3. Importance Score Calculation**
$$
I_{\text{total}} = w_1 \cdot I_{\text{content}} + w_2 \cdot I_{\text{context}} + w_3 \cdot I_{\text{temporal}}
$$
Trong ƒë√≥:
- $I_{\text{content}}$ - Content-based importance t·ª´ LLM
- $I_{\text{context}}$ - Context relevance 
- $I_{\text{temporal}}$ - Temporal decay factor

#### **4. Temporal Weighting**
$$
w_{\text{temporal}}(t) = e^{-\lambda \cdot (t_{\text{current}} - t_{\text{memory}})}
$$
Trong ƒë√≥:
- $\lambda = 0.05$ - Decay rate
- $t$ - Timestamp

#### **5. Memory Capacity Utilization**
$$
U = \frac{N_{\text{current}}}{N_{\text{max}}} \times 100\%
$$
Cleanup trigger khi $U \geq 90\%$

### üîÑ **Quy tr√¨nh Memory Management**

#### **Phase 1: Information Extraction**
1. **LLM Extraction**: S·ª≠ d·ª•ng GPT-4o-mini extract key info
   - Entities, intent, key facts, topics
   - Sentiment analysis  
   - Importance scoring (0-1)
   - Memory type classification

#### **Phase 2: Memory Retrieval**  
2. **Vector Search**: ChromaDB retrieval top-k similar memories
3. **Similarity Scoring**: Cosine similarity calculation
4. **Context Analysis**: Evaluate relevance v√† redundancy

#### **Phase 3: Decision Making (Algorithm 1)**
5. **Operation Decision**: 
   - **ADD**: Th√¥ng tin m·ªõi, similarity th·∫•p
   - **UPDATE**: Similarity trung b√¨nh, c√≥ th√¥ng tin b·ªï sung
   - **DELETE**: Similarity cao, th√¥ng tin kh√¥ng quan tr·ªçng h∆°n
   - **NOOP**: ƒê√£ c√≥ memory t∆∞∆°ng t·ª± ƒë·ªß t·ªët

#### **Phase 4: Execution & Storage**
6. **Memory Operations**: Execute decided operation
7. **Knowledge DB**: Store structured knowledge + operation logs
8. **Meta-learning**: Update adaptive parameters
9. **Temporal Weighting**: Apply time-based scoring

### üíæ **Storage Architecture**

```
Memory Storage:
‚îú‚îÄ‚îÄ ChromaDB (Vector Store)
‚îÇ   ‚îú‚îÄ‚îÄ Embeddings (384D/768D)
‚îÇ   ‚îú‚îÄ‚îÄ Metadata
‚îÇ   ‚îî‚îÄ‚îÄ Similarity Search
‚îú‚îÄ‚îÄ Knowledge Database (SQLite)
‚îÇ   ‚îú‚îÄ‚îÄ Extracted Knowledge
‚îÇ   ‚îú‚îÄ‚îÄ Memory Operations Log  
‚îÇ   ‚îî‚îÄ‚îÄ Session Management
‚îî‚îÄ‚îÄ Experience Buffer (Pickle)
    ‚îú‚îÄ‚îÄ RL Training Data
    ‚îî‚îÄ‚îÄ Temporal Experiences
```

### üéØ **Performance Metrics**

**Efficiency Metrics:**
- **ADD Ratio**: $\frac{\text{ADD operations}}{\text{Total operations}}$
- **UPDATE Ratio**: $\frac{\text{UPDATE operations}}{\text{Total operations}}$ 
- **NOOP Ratio**: $\frac{\text{NOOP operations}}{\text{Total operations}}$
- **Memory Utilization**: $\frac{\text{Used capacity}}{\text{Max capacity}} \times 100\%$

**Quality Metrics:**
- **Avg Response Time**: Tracking performance
- **Memory Retrievals**: Usage frequency
- **Consolidation Runs**: Memory optimization events

[1 tool called]

### üöÄ **Key Features**

1. **Intelligent Decision Making**: Algorithm 1 t·ª± ƒë·ªông quy·∫øt ƒë·ªãnh memory operations
2. **Multi-layered Storage**: Vector + Structured + Temporal storage
3. **LLM-powered Analysis**: Automatic information extraction
4. **Session Management**: Database-persistent conversations  
5. **Adaptive Learning**: Meta-learning v·ªõi episodic memory
6. **Temporal Decay**: Time-weighted importance scoring
7. **Capacity Management**: Automatic cleanup khi full

H·ªá th·ªëng n√†y t·∫°o ra m·ªôt **intelligent memory bank** c√≥ kh·∫£ nƒÉng t·ª± qu·∫£n l√Ω, t·ªëi ∆∞u h√≥a v√† h·ªçc h·ªèi t·ª´ interactions, ƒë·∫£m b·∫£o memory quality cao v√† performance t·ªët cho conversational AI.